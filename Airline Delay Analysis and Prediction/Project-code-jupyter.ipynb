{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df=spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",'True').load('2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>...</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>ACTUAL_ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>2429</td>\n",
       "      <td>EWR</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1517</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>...</td>\n",
       "      <td>268.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>2427</td>\n",
       "      <td>LAS</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1115</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>2426</td>\n",
       "      <td>SNA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1335</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>...</td>\n",
       "      <td>134.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>2425</td>\n",
       "      <td>RSW</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1546</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>...</td>\n",
       "      <td>190.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>2424</td>\n",
       "      <td>ORD</td>\n",
       "      <td>ALB</td>\n",
       "      <td>630</td>\n",
       "      <td>650.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  CRS_DEP_TIME  \\\n",
       "0 2018-01-01         UA               2429    EWR  DEN          1517   \n",
       "1 2018-01-01         UA               2427    LAS  SFO          1115   \n",
       "2 2018-01-01         UA               2426    SNA  DEN          1335   \n",
       "3 2018-01-01         UA               2425    RSW  ORD          1546   \n",
       "4 2018-01-01         UA               2424    ORD  ALB           630   \n",
       "\n",
       "   DEP_TIME  DEP_DELAY  TAXI_OUT  WHEELS_OFF  ...  CRS_ELAPSED_TIME  \\\n",
       "0    1512.0       -5.0      15.0      1527.0  ...             268.0   \n",
       "1    1107.0       -8.0      11.0      1118.0  ...              99.0   \n",
       "2    1330.0       -5.0      15.0      1345.0  ...             134.0   \n",
       "3    1552.0        6.0      19.0      1611.0  ...             190.0   \n",
       "4     650.0       20.0      13.0       703.0  ...             112.0   \n",
       "\n",
       "   ACTUAL_ELAPSED_TIME  AIR_TIME  DISTANCE  CARRIER_DELAY  WEATHER_DELAY  \\\n",
       "0                250.0     225.0    1605.0            NaN            NaN   \n",
       "1                 83.0      65.0     414.0            NaN            NaN   \n",
       "2                126.0     106.0     846.0            NaN            NaN   \n",
       "3                182.0     157.0    1120.0            NaN            NaN   \n",
       "4                106.0      83.0     723.0            NaN            NaN   \n",
       "\n",
       "  NAS_DELAY  SECURITY_DELAY  LATE_AIRCRAFT_DELAY  Unnamed: 27  \n",
       "0       NaN             NaN                  NaN         None  \n",
       "1       NaN             NaN                  NaN         None  \n",
       "2       NaN             NaN                  NaN         None  \n",
       "3       NaN             NaN                  NaN         None  \n",
       "4       NaN             NaN                  NaN         None  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.limit(5).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7213446"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7213446"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.distinct().count()\n",
    "#This shows there are no duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: timestamp (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_TIME: double (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- TAXI_OUT: double (nullable = true)\n",
      " |-- WHEELS_OFF: double (nullable = true)\n",
      " |-- WHEELS_ON: double (nullable = true)\n",
      " |-- TAXI_IN: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_TIME: double (nullable = true)\n",
      " |-- ARR_DELAY: double (nullable = true)\n",
      " |-- CANCELLED: double (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- DIVERTED: double (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: double (nullable = true)\n",
      " |-- AIR_TIME: double (nullable = true)\n",
      " |-- DISTANCE: double (nullable = true)\n",
      " |-- CARRIER_DELAY: double (nullable = true)\n",
      " |-- WEATHER_DELAY: double (nullable = true)\n",
      " |-- NAS_DELAY: double (nullable = true)\n",
      " |-- SECURITY_DELAY: double (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: double (nullable = true)\n",
      " |-- Unnamed: 27: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FL_DATE ------------- 0.0\n",
      "OP_CARRIER ---------- 0.0\n",
      "OP_CARRIER_FL_NUM --- 0.0\n",
      "ORIGIN -------------- 0.0\n",
      "DEST ---------------- 0.0\n",
      "CRS_DEP_TIME -------- 0.0\n",
      "DEP_TIME ------------ 1.5570505414471807\n",
      "DEP_DELAY ----------- 1.6252149111534209\n",
      "TAXI_OUT ------------ 1.6057512595228411\n",
      "WHEELS_OFF ---------- 1.605737396523104\n",
      "WHEELS_ON ----------- 1.653107266624024\n",
      "TAXI_IN ------------- 1.653107266624024\n",
      "CRS_ARR_TIME -------- 0.0\n",
      "ARR_TIME ------------ 1.653093403624287\n",
      "ARR_DELAY ----------- 1.8997854839420716\n",
      "CANCELLED ----------- 0.0\n",
      "CANCELLATION_CODE --- 98.38379603867556\n",
      "DIVERTED ------------ 0.0\n",
      "CRS_ELAPSED_TIME ---- 0.00013862999736880265\n",
      "ACTUAL_ELAPSED_TIME - 1.8637694106256566\n",
      "AIR_TIME ------------ 1.8637694106256566\n",
      "DISTANCE ------------ 0.0\n",
      "CARRIER_DELAY ------- 81.2473816259247\n",
      "WEATHER_DELAY ------- 81.2473816259247\n",
      "NAS_DELAY ----------- 81.2473816259247\n",
      "SECURITY_DELAY ------ 81.2473816259247\n",
      "LATE_AIRCRAFT_DELAY - 81.2473816259247\n",
      "Unnamed: 27 --------- 100.0\n"
     ]
    }
   ],
   "source": [
    "c=df.count()\n",
    "for i in df.columns:\n",
    "    print(i,(20-len(i))*\"-\",((df.filter(df[i].isNull()).count())/c)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
      "|            FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|\n",
      "+-------------------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
      "|2018-01-01 00:00:00|        UA|             2429|   EWR| DEN|        1517|  1512.0|     -5.0|    15.0|    1527.0|   1712.0|   10.0|        1745|  1722.0|    -23.0|      0.0|     0.0|           268.0|              250.0|   225.0|  1605.0|\n",
      "|2018-01-01 00:00:00|        UA|             2427|   LAS| SFO|        1115|  1107.0|     -8.0|    11.0|    1118.0|   1223.0|    7.0|        1254|  1230.0|    -24.0|      0.0|     0.0|            99.0|               83.0|    65.0|   414.0|\n",
      "|2018-01-01 00:00:00|        UA|             2426|   SNA| DEN|        1335|  1330.0|     -5.0|    15.0|    1345.0|   1631.0|    5.0|        1649|  1636.0|    -13.0|      0.0|     0.0|           134.0|              126.0|   106.0|   846.0|\n",
      "|2018-01-01 00:00:00|        UA|             2425|   RSW| ORD|        1546|  1552.0|      6.0|    19.0|    1611.0|   1748.0|    6.0|        1756|  1754.0|     -2.0|      0.0|     0.0|           190.0|              182.0|   157.0|  1120.0|\n",
      "|2018-01-01 00:00:00|        UA|             2424|   ORD| ALB|         630|   650.0|     20.0|    13.0|     703.0|    926.0|   10.0|         922|   936.0|     14.0|      0.0|     0.0|           112.0|              106.0|    83.0|   723.0|\n",
      "|2018-01-01 00:00:00|        UA|             2422|   ORD| OMA|        2241|  2244.0|      3.0|    15.0|    2259.0|      1.0|    2.0|          14|     3.0|    -11.0|      0.0|     0.0|            93.0|               79.0|    62.0|   416.0|\n",
      "|2018-01-01 00:00:00|        UA|             2421|   IAH| LAS|         750|   747.0|     -3.0|    14.0|     801.0|    854.0|    6.0|         916|   900.0|    -16.0|      0.0|     0.0|           206.0|              193.0|   173.0|  1222.0|\n",
      "|2018-01-01 00:00:00|        UA|             2420|   DEN| CID|        1324|  1318.0|     -6.0|    11.0|    1329.0|   1554.0|    6.0|        1619|  1600.0|    -19.0|      0.0|     0.0|           115.0|              102.0|    85.0|   692.0|\n",
      "|2018-01-01 00:00:00|        UA|             2419|   SMF| EWR|        2224|  2237.0|     13.0|    10.0|    2247.0|    627.0|    9.0|         638|   636.0|     -2.0|      0.0|     0.0|           314.0|              299.0|   280.0|  2500.0|\n",
      "|2018-01-01 00:00:00|        UA|             2418|   RIC| DEN|        1601|  1559.0|     -2.0|    12.0|    1611.0|   1748.0|    8.0|        1813|  1756.0|    -17.0|      0.0|     0.0|           252.0|              237.0|   217.0|  1482.0|\n",
      "|2018-01-01 00:00:00|        UA|             2417|   PDX| EWR|        2240|  2235.0|     -5.0|     9.0|    2244.0|    624.0|    7.0|         647|   631.0|    -16.0|      0.0|     0.0|           307.0|              296.0|   280.0|  2434.0|\n",
      "|2018-01-01 00:00:00|        UA|             2416|   ORD| CLE|        2059|  2300.0|    121.0|    24.0|    2324.0|    112.0|    8.0|        2311|   120.0|    129.0|      0.0|     0.0|            72.0|               80.0|    48.0|   316.0|\n",
      "|2018-01-01 00:00:00|        UA|             2415|   EWR| PDX|         825|   822.0|     -3.0|    15.0|     837.0|   1104.0|    5.0|        1135|  1109.0|    -26.0|      0.0|     0.0|           370.0|              347.0|   327.0|  2434.0|\n",
      "|2018-01-01 00:00:00|        UA|             2414|   EWR| ATL|        1044|  1055.0|     11.0|    11.0|    1106.0|   1310.0|    5.0|        1318|  1315.0|     -3.0|      0.0|     0.0|           154.0|              140.0|   124.0|   746.0|\n",
      "|2018-01-01 00:00:00|        UA|             2413|   ORD| BTV|        2114|  2230.0|     76.0|    14.0|    2244.0|    123.0|    5.0|          15|   128.0|     73.0|      0.0|     0.0|           121.0|              118.0|    99.0|   763.0|\n",
      "|2018-01-01 00:00:00|        UA|             2412|   MCO| LAX|         653|   747.0|     54.0|    14.0|     801.0|   1003.0|   22.0|         930|  1025.0|     55.0|      0.0|     0.0|           337.0|              338.0|   302.0|  2218.0|\n",
      "|2018-01-01 00:00:00|        UA|             2411|   EWR| SMF|        1810|  1922.0|     72.0|    16.0|    1938.0|   2157.0|    4.0|        2136|  2201.0|     25.0|      0.0|     0.0|           386.0|              339.0|   319.0|  2500.0|\n",
      "|2018-01-01 00:00:00|        UA|             2410|   RSW| EWR|        1250|  1337.0|     47.0|    12.0|    1349.0|   1600.0|    6.0|        1537|  1606.0|     29.0|      0.0|     0.0|           167.0|              149.0|   131.0|  1068.0|\n",
      "|2018-01-01 00:00:00|        UA|             2409|   IAH| JAC|         940|   934.0|     -6.0|    18.0|     952.0|   1156.0|    4.0|        1218|  1200.0|    -18.0|      0.0|     0.0|           218.0|              206.0|   184.0|  1265.0|\n",
      "|2018-01-01 00:00:00|        UA|             2408|   TYS| EWR|        1131|  1140.0|      9.0|     9.0|    1149.0|   1307.0|    5.0|        1333|  1312.0|    -21.0|      0.0|     0.0|           122.0|               92.0|    78.0|   631.0|\n",
      "+-------------------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c=df.count()\n",
    "for i in df.columns:\n",
    "    if (((df.filter(df[i].isNull()).count())/c)*100)>80:\n",
    "        df=df.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FL_DATE ------------- 0.0\n",
      "OP_CARRIER ---------- 0.0\n",
      "OP_CARRIER_FL_NUM --- 0.0\n",
      "ORIGIN -------------- 0.0\n",
      "DEST ---------------- 0.0\n",
      "CRS_DEP_TIME -------- 0.0\n",
      "DEP_TIME ------------ 1.5570505414471807\n",
      "DEP_DELAY ----------- 1.6252149111534209\n",
      "TAXI_OUT ------------ 1.6057512595228411\n",
      "WHEELS_OFF ---------- 1.605737396523104\n",
      "WHEELS_ON ----------- 1.653107266624024\n",
      "TAXI_IN ------------- 1.653107266624024\n",
      "CRS_ARR_TIME -------- 0.0\n",
      "ARR_TIME ------------ 1.653093403624287\n",
      "ARR_DELAY ----------- 1.8997854839420716\n",
      "CANCELLED ----------- 0.0\n",
      "DIVERTED ------------ 0.0\n",
      "CRS_ELAPSED_TIME ---- 0.00013862999736880265\n",
      "ACTUAL_ELAPSED_TIME - 1.8637694106256566\n",
      "AIR_TIME ------------ 1.8637694106256566\n",
      "DISTANCE ------------ 0.0\n"
     ]
    }
   ],
   "source": [
    "c=df.count()\n",
    "for i in df.columns:\n",
    "    print(i,(20-len(i))*\"-\",((df.filter(df[i].isNull()).count())/c)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df=df.withColumn(\"FL_DATE\",to_date(col(\"FL_DATE\"),\"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[FL_DATE: date, OP_CARRIER: string, OP_CARRIER_FL_NUM: int, ORIGIN: string, DEST: string, CRS_DEP_TIME: int, DEP_TIME: double, DEP_DELAY: double, TAXI_OUT: double, WHEELS_OFF: double, WHEELS_ON: double, TAXI_IN: double, CRS_ARR_TIME: int, ARR_TIME: double, ARR_DELAY: double, CANCELLED: double, DIVERTED: double, CRS_ELAPSED_TIME: double, ACTUAL_ELAPSED_TIME: double, AIR_TIME: double, DISTANCE: double]>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "df = df.withColumn(\"OP_CARRIER_FL_NUM\",df[\"OP_CARRIER_FL_NUM\"].cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('OP_CARRIER_FL_NUM', 'string')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('OP_CARRIER_FL_NUM').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|OP_CARRIER|\n",
      "+----------+\n",
      "|        UA|\n",
      "|        NK|\n",
      "|        AA|\n",
      "|        EV|\n",
      "|        B6|\n",
      "|        DL|\n",
      "|        OO|\n",
      "|        F9|\n",
      "|        YV|\n",
      "|        MQ|\n",
      "|        OH|\n",
      "|        HA|\n",
      "|        G4|\n",
      "|        YX|\n",
      "|        AS|\n",
      "|        VX|\n",
      "|        WN|\n",
      "|        9E|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('OP_CARRIER').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "l={'UA':'United Airlines',\n",
    "    'AS':'Alaska Airlines',\n",
    "    '9E':'Endeavor Air',\n",
    "    'B6':'JetBlue Airways',\n",
    "    'EV':'ExpressJet',\n",
    "    'F9':'Frontier Airlines',\n",
    "    'G4':'Allegiant Air',\n",
    "    'HA':'Hawaiian Airlines',\n",
    "    'MQ':'Envoy Air',\n",
    "    'NK':'Spirit Airlines',\n",
    "    'OH':'PSA Airlines',\n",
    "    'OO':'SkyWest Airlines',\n",
    "    'VX':'Virgin America',\n",
    "    'WN':'Southwest Airlines',\n",
    "    'YV':'Mesa Airline',\n",
    "    'YX':'Republic Airways',\n",
    "    'AA':'American Airlines',\n",
    "    'DL':'Delta Airlines'}\n",
    "l=list(l.items())\n",
    "for i in range(18):\n",
    "    df=df.withColumn('OP_CARRIER', regexp_replace('OP_CARRIER', l[i][0], l[i][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        OP_CARRIER|\n",
      "+------------------+\n",
      "|      Mesa Airline|\n",
      "|     Allegiant Air|\n",
      "|   United Airlines|\n",
      "|    Virgin America|\n",
      "| Hawaiian Airlines|\n",
      "|  Republic Airways|\n",
      "|        ExpressJet|\n",
      "|  SkyWest Airlines|\n",
      "| Frontier Airlines|\n",
      "|      Endeavor Air|\n",
      "| American Airlines|\n",
      "|   JetBlue Airways|\n",
      "|         Envoy Air|\n",
      "|    Delta Airlines|\n",
      "|      PSA Airlines|\n",
      "|   Alaska Airlines|\n",
      "|   Spirit Airlines|\n",
      "|Southwest Airlines|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('OP_CARRIER').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
      "|   FL_DATE|     OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|\n",
      "+----------+---------------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
      "|2018-01-01|United Airlines|             2424|   ORD| ALB|         630|   650.0|     20.0|    13.0|     703.0|    926.0|   10.0|         922|   936.0|     14.0|      0.0|     0.0|           112.0|              106.0|    83.0|   723.0|\n",
      "|2018-01-01|United Airlines|             2416|   ORD| CLE|        2059|  2300.0|    121.0|    24.0|    2324.0|    112.0|    8.0|        2311|   120.0|    129.0|      0.0|     0.0|            72.0|               80.0|    48.0|   316.0|\n",
      "|2018-01-01|United Airlines|             2413|   ORD| BTV|        2114|  2230.0|     76.0|    14.0|    2244.0|    123.0|    5.0|          15|   128.0|     73.0|      0.0|     0.0|           121.0|              118.0|    99.0|   763.0|\n",
      "|2018-01-01|United Airlines|             2412|   MCO| LAX|         653|   747.0|     54.0|    14.0|     801.0|   1003.0|   22.0|         930|  1025.0|     55.0|      0.0|     0.0|           337.0|              338.0|   302.0|  2218.0|\n",
      "|2018-01-01|United Airlines|             2411|   EWR| SMF|        1810|  1922.0|     72.0|    16.0|    1938.0|   2157.0|    4.0|        2136|  2201.0|     25.0|      0.0|     0.0|           386.0|              339.0|   319.0|  2500.0|\n",
      "|2018-01-01|United Airlines|             2410|   RSW| EWR|        1250|  1337.0|     47.0|    12.0|    1349.0|   1600.0|    6.0|        1537|  1606.0|     29.0|      0.0|     0.0|           167.0|              149.0|   131.0|  1068.0|\n",
      "|2018-01-01|United Airlines|             2406|   EWR| TYS|         830|   844.0|     14.0|    20.0|     904.0|   1052.0|    3.0|        1049|  1055.0|      6.0|      0.0|     0.0|           139.0|              131.0|   108.0|   631.0|\n",
      "|2018-01-01|United Airlines|             2402|   JAC| EWR|        1343|  1351.0|      8.0|    38.0|    1429.0|   2003.0|   10.0|        1959|  2013.0|     14.0|      0.0|     0.0|           256.0|              262.0|   214.0|  1874.0|\n",
      "|2018-01-01|United Airlines|             2398|   MSY| EWR|        2043|  2131.0|     48.0|    10.0|    2141.0|     54.0|    7.0|          34|   101.0|     27.0|      0.0|     0.0|           171.0|              150.0|   133.0|  1167.0|\n",
      "|2018-01-01|United Airlines|             2384|   EWR| FLL|        1627|  1624.0|     -3.0|    38.0|    1702.0|   1938.0|    6.0|        1938|  1944.0|      6.0|      0.0|     0.0|           191.0|              200.0|   156.0|  1065.0|\n",
      "|2018-01-01|United Airlines|             2160|   ORD| MCI|        2030|  2111.0|     41.0|    21.0|    2132.0|   2230.0|    5.0|        2209|  2235.0|     26.0|      0.0|     0.0|            99.0|               84.0|    58.0|   403.0|\n",
      "|2018-01-01|United Airlines|             2155|   IND| ORD|        1822|  1956.0|     94.0|     9.0|    2005.0|   1947.0|    3.0|        1835|  1950.0|     75.0|      0.0|     0.0|            73.0|               54.0|    42.0|   177.0|\n",
      "|2018-01-01|United Airlines|             2154|   IAD| FLL|        1729|  1745.0|     16.0|    20.0|    1805.0|   2014.0|    6.0|        2009|  2020.0|     11.0|      0.0|     0.0|           160.0|              155.0|   129.0|   901.0|\n",
      "|2018-01-01|United Airlines|             2153|   EWR| BTV|        2145|  2359.0|    134.0|    12.0|      11.0|    102.0|    4.0|        2302|   106.0|    124.0|      0.0|     0.0|            77.0|               67.0|    51.0|   266.0|\n",
      "|2018-01-01|United Airlines|             2150|   LAX| SAN|         602|  1101.0|    299.0|    19.0|    1120.0|   1149.0|    3.0|         701|  1152.0|    291.0|      0.0|     0.0|            59.0|               51.0|    29.0|   109.0|\n",
      "|2018-01-01|United Airlines|             2148|   SAN| EWR|        2100|  2111.0|     11.0|    13.0|    2124.0|    453.0|    7.0|         459|   500.0|      1.0|      0.0|     0.0|           299.0|              289.0|   269.0|  2425.0|\n",
      "|2018-01-01|United Airlines|             2147|   EWR| ORD|        1646|  1658.0|     12.0|    17.0|    1715.0|   1811.0|   25.0|        1827|  1836.0|      9.0|      0.0|     0.0|           161.0|              158.0|   116.0|   719.0|\n",
      "|2018-01-01|United Airlines|             2145|   BDL| EWR|         600|   621.0|     21.0|    14.0|     635.0|    717.0|    4.0|         717|   721.0|      4.0|      0.0|     0.0|            77.0|               60.0|    42.0|   116.0|\n",
      "|2018-01-01|United Airlines|             2143|   SFO| SAN|         835|   830.0|     -5.0|    51.0|     921.0|   1032.0|    3.0|        1007|  1035.0|     28.0|      0.0|     0.0|            92.0|              125.0|    71.0|   447.0|\n",
      "|2018-01-01|United Airlines|             2137|   DEN| BZN|        2228|  2227.0|     -1.0|    33.0|    2300.0|     19.0|    6.0|          16|    25.0|      9.0|      0.0|     0.0|           108.0|              118.0|    79.0|   524.0|\n",
      "+----------+---------------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+--------+----------------+-------------------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1=df.filter(df['ARR_DELAY']>0)\n",
    "df1.show() #df_new contains delayed flights only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year\n",
    "from pyspark.sql.functions import month\n",
    "from pyspark.sql.functions import dayofweek\n",
    "df1=df1.withColumn('FL_YEAR',year(df1.FL_DATE))\n",
    "df1=df1.withColumn('FL_DAYOFWEEK',dayofweek(df1.FL_DATE))\n",
    "df1=df1.withColumn('FL_MONTH',month(df1.FL_DATE))\n",
    "\n",
    "#Extract day of week and month\n",
    "df=df.withColumn('FL_DAYOFWEEK',dayofweek(df.FL_DATE))\n",
    "df=df.withColumn('FL_MONTH',month(df.FL_DATE))\n",
    "\n",
    "#Cast to double\n",
    "df=df.withColumn(\"FL_MONTH\",col(\"FL_MONTH\").cast('double'))\n",
    "df=df.withColumn(\"FL_DAYOFWEEK\",col(\"FL_DAYOFWEEK\").cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: date (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_TIME: double (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- TAXI_OUT: double (nullable = true)\n",
      " |-- WHEELS_OFF: double (nullable = true)\n",
      " |-- WHEELS_ON: double (nullable = true)\n",
      " |-- TAXI_IN: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_TIME: double (nullable = true)\n",
      " |-- ARR_DELAY: double (nullable = true)\n",
      " |-- CANCELLED: double (nullable = true)\n",
      " |-- DIVERTED: double (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: double (nullable = true)\n",
      " |-- AIR_TIME: double (nullable = true)\n",
      " |-- DISTANCE: double (nullable = true)\n",
      " |-- FL_DAYOFWEEK: double (nullable = true)\n",
      " |-- FL_MONTH: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd1 = df.withColumn('Delayed', (df.ARR_DELAY >=15).cast('double')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Delayed|\n",
      "+-------+\n",
      "|    0.0|\n",
      "|   null|\n",
      "|    1.0|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bd1.select('Delayed').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Delayed', 'double')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd1.select('Delayed').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd1.createOrReplaceTempView(\"bd1\")\n",
    "\n",
    "bd1 = spark.sql(\"select *, case \\\n",
    "               when DEP_TIME <= 800 then 1 \\\n",
    "               when 800 < DEP_TIME and DEP_TIME <= 1200 then 2 \\\n",
    "               when 1200 < DEP_TIME and DEP_TIME <= 1600 then 3 \\\n",
    "               when 1600 < DEP_TIME and DEP_TIME <= 2100 then 4 \\\n",
    "               else 1 end as TimeSlot \\\n",
    "               from bd1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+-------+\n",
      "|        OP_CARRIER|INDEX_CARRIER|  count|\n",
      "+------------------+-------------+-------+\n",
      "|Southwest Airlines|          0.0|1352552|\n",
      "|    Delta Airlines|          1.0| 949283|\n",
      "| American Airlines|          2.0| 916818|\n",
      "|  SkyWest Airlines|          3.0| 774137|\n",
      "|   United Airlines|          4.0| 621565|\n",
      "|  Republic Airways|          5.0| 316090|\n",
      "|   JetBlue Airways|          6.0| 305010|\n",
      "|         Envoy Air|          7.0| 296001|\n",
      "|      PSA Airlines|          8.0| 278457|\n",
      "|      Endeavor Air|          9.0| 245917|\n",
      "|   Alaska Airlines|         10.0| 245761|\n",
      "|      Mesa Airline|         11.0| 215138|\n",
      "|        ExpressJet|         12.0| 202890|\n",
      "|   Spirit Airlines|         13.0| 176178|\n",
      "| Frontier Airlines|         14.0| 120035|\n",
      "|     Allegiant Air|         15.0|  96221|\n",
      "| Hawaiian Airlines|         16.0|  83723|\n",
      "|    Virgin America|         17.0|  17670|\n",
      "+------------------+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer1 = StringIndexer(inputCol='OP_CARRIER',outputCol='INDEX_CARRIER') \n",
    "bd2=indexer1.fit(bd1).transform(bd1)\n",
    "\n",
    "indexer2 = StringIndexer(inputCol='ORIGIN',outputCol='INDEX_ORIGIN') \n",
    "bd3=indexer2.fit(bd2).transform(bd2)\n",
    "\n",
    "bd3.groupBy('OP_CARRIER','INDEX_CARRIER').count().sort('INDEX_CARRIER').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Seleciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd4=bd3.select('DEP_DELAY',\n",
    "             'DISTANCE', \n",
    "             'FL_DAYOFWEEK',\n",
    "             'INDEX_CARRIER', \n",
    "             'TimeSlot',\n",
    "             'FL_MONTH',\n",
    "             'ACTUAL_ELAPSED_TIME',\n",
    "             'INDEX_ORIGIN',\n",
    "             'Delayed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "imputer = Imputer(\n",
    "    inputCols = bd4.columns,\n",
    "    outputCols = [\"{}\".format(a) for a in bd4.columns]\n",
    ").setStrategy(\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5=imputer.fit(bd4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd6=b5.transform(bd4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom pyspark.ml.feature import OneHotEncoder\\nencoder = OneHotEncoder(dropLast=False, inputCol=\"INDEX_ORIGIN\", outputCol=\"VEC_ORIGIN\")\\nbd7 = encoder.fit(bd6).transform(bd6)\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "encoder = OneHotEncoder(dropLast=False, inputCol=\"INDEX_ORIGIN\", outputCol=\"VEC_ORIGIN\")\n",
    "bd7 = encoder.fit(bd6).transform(bd6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor and Response Variable Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer  \n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "a1 = VectorAssembler(  \n",
    "inputCols=['DEP_DELAY',\n",
    "             'DISTANCE', \n",
    "             'FL_DAYOFWEEK',\n",
    "             'INDEX_CARRIER', \n",
    "             'TimeSlot',\n",
    "             'FL_MONTH',\n",
    "             'ACTUAL_ELAPSED_TIME',\n",
    "             'INDEX_ORIGIN'], \n",
    "outputCol='features')\n",
    "\n",
    "bd8 = a1.transform(bd7).select(col(\"Delayed\").alias(\"label\"),'features')  \n",
    "bd9 = bd8.select('label','features')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|features                                |\n",
      "+----------------------------------------+\n",
      "|[-5.0,1605.0,2.0,4.0,3.0,1.0,250.0,14.0]|\n",
      "|[-8.0,414.0,2.0,4.0,2.0,1.0,83.0,10.0]  |\n",
      "|[-5.0,846.0,2.0,4.0,3.0,1.0,126.0,46.0] |\n",
      "|[6.0,1120.0,2.0,4.0,3.0,1.0,182.0,49.0] |\n",
      "|[20.0,723.0,2.0,4.0,1.0,1.0,106.0,1.0]  |\n",
      "|[3.0,416.0,2.0,4.0,1.0,1.0,79.0,1.0]    |\n",
      "|[-3.0,1222.0,2.0,4.0,1.0,1.0,193.0,8.0] |\n",
      "|[-6.0,692.0,2.0,4.0,3.0,1.0,102.0,3.0]  |\n",
      "|[13.0,2500.0,2.0,4.0,1.0,1.0,299.0,44.0]|\n",
      "|[-2.0,1482.0,2.0,4.0,3.0,1.0,237.0,61.0]|\n",
      "+----------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bd9.select('features').show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Count: 5048667\n",
      "Test Dataset Count: 2164779\n"
     ]
    }
   ],
   "source": [
    "train, test = bd9.randomSplit([0.7, 0.3], seed = 123)\n",
    "print(\"Train Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|[-50.0,198.0,3.0,...|\n",
      "|  0.0|[-49.0,198.0,4.0,...|\n",
      "|  0.0|[-46.0,345.0,4.0,...|\n",
      "|  0.0|[-46.0,430.0,5.0,...|\n",
      "|  0.0|[-45.0,83.0,6.0,3...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr=LogisticRegression (featuresCol = 'features', labelCol ='label', maxIter=5)\n",
    "lrModel=lr.fit(train)\n",
    "\n",
    "pred_lr=lrModel.transform(test)\n",
    "pred_lr.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC Curve (Logistic Regression model): 0.9606\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "# Let's use the run-of-the-mill evaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='label')\n",
    "auroc_lr = evaluator.evaluate(pred_lr, {evaluator.metricName: \"areaUnderROC\"})\n",
    "print(\"Area under ROC Curve (Logistic Regression model): {:.4f}\".format(auroc_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----------------------------------------+\n",
      "|label|prediction|probability                              |\n",
      "+-----+----------+-----------------------------------------+\n",
      "|0.0  |0.0       |[0.9815257409495219,0.018474259050478028]|\n",
      "|0.0  |0.0       |[0.9815257409495219,0.018474259050478028]|\n",
      "|0.0  |0.0       |[0.9815257409495219,0.018474259050478028]|\n",
      "|0.0  |0.0       |[0.9815257409495219,0.018474259050478028]|\n",
      "|0.0  |0.0       |[0.9815257409495219,0.018474259050478028]|\n",
      "+-----+----------+-----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(labelCol=\"label\",featuresCol=\"features\",maxDepth=5,maxBins=32)\n",
    "tree_model = tree.fit(train)\n",
    "# Create predictions on test data\n",
    "pred_dt= tree_model.transform(test)\n",
    "pred_dt.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC Curve (Decision Tree Classifier Regression model): 0.7144\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Let's use the run-of-the-mill evaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='label2')\n",
    "auroc_dt = evaluator.evaluate(pred_dt, {evaluator.metricName: \"areaUnderROC\"})\n",
    "print(\"Area under ROC Curve (Decision Tree Classifier Regression model): {:.4f}\".format(auroc_dt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df9189e9d2677d04d2d37cbfdaa68a900e4b88f0b512d1a6c6fcc9a87738dc59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
